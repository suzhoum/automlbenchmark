---
project_repository: https://github.com/Innixma/automlbenchmark#2024_10_24    # this is also the url used to clone the repository on ec2 instances
                                                                          # when running those without docker.
                                                                          # to clone a specific branch/tag, add a url fragment, e.g.:
                                                                          # https://github.com/openml/automlbenchmark#stable

frameworks:              # configuration namespace for the frameworks definitions.
  definition_file:       # list of yaml files describing the frameworks base definitions.
    - '{root}/resources/frameworks.yaml'
    - '{user}/frameworks.yaml'
  allow_duplicates: true     # if true, the last definition is used.
  tags: ['stable', 'latest', 'ftt', 'zeroshot', 'zeroshot_v2', 'zeroshot_ftt', 'stackinfo', 'tabrepo', 'autogluon_v1', '2020Q2', '2021Q3',  '2023Q2', '2022AG']  # the list of supported tags when looking up frameworks:
                              # for example frmwk:latest will look for framework frmwk in a frameworks_latest.yaml file if present.

benchmarks:                     # configuration namespace for the benchmarks definitions.
  definition_dir:               # list of directories containing the benchmarks yaml definitions.
    - '{root}/resources/benchmarks'
    - '{user}/benchmarks'
  constraints_file:             # list of yaml files describing the benchmarks runtime constraints.
    - '{root}/resources/constraints.yaml'
    - '{user}/constraints.yaml'
  overhead_time_seconds: 72000   # amount of additional time allowed for the job to complete before sending an interruption signal
  timeout_multiplier: 6          # multiplier to the time_limit used to interrupt the job due to timeout if exceeded. 2 by default.

job_scheduler:           # configuration namespace
  max_parallel_jobs: 3000  # safety limit: increase this if you want to be able to run many jobs in parallel, especially in aws mode. Defaults to 10 to allow running the usual 10 folds in parallel with no problem.
  delay_between_jobs: 8  # delay in seconds between each parallel job start

versions:              # configuration namespace for versions enforcement (libraries versions are usually enforced in requirements.txt for the app and for each framework).
  pip:
  python: 3.9          # the Python minor version that will be used by the application in containers and cloud instances, , also used as a based version for virtual environments created for each framework.

aws:                    # configuration namespace for AWS mode.
  region: 'us-east-1'            # the AWS region to use. By default, the app will use the region set in ~/.aws/config when configuring AWS CLI.
  # region: 'eu-west-1'

  iam:                                               # sub-namespace for AWS IAM service.
    max_role_session_duration_secs: 259200             # the max duration (in seconds) during which the ec2 instance will have access to s3.
                                                     # This should be a number between 900 (15mn) to 43200 (12h).

  s3:                               # sub-namespace for AWS S3 service.
    bucket: automl-benchmark-ag        # must be unique im whole Amazon s3, max 40 chars, and include only numbers, lowercase characters and hyphens.
    root_key: ec2/2024_10_24/                  #

  ec2:
    instance_type:                       #
      series: m6i                        # m6i
      map:                               # map between num cores required and ec2 instance type sizes
        default: large
        '1': small
        '2': large
        '4': xlarge
        '8': 2xlarge
        '16': 4xlarge
        '32': 8xlarge
        '64': 16xlarge
    volume_type: gp3                # one of gp2, io1, st1, sc1, or standard (default).
    # key_name: neerick_dev           # the name of the key pair passed to EC2 instances (if not set, user can't ssh the running instances)

    # Note: Added a new updated region image, old images no longer responded to SSH and didn't work correctly
    regions:                             #
      us-east-1:
        ami: ami-005fc0f236362e99f
        description: Canonical, Ubuntu, 22.04 LTS, amd64 jammy image build on 2024-09-27
      eu-west-1:
        ami: ami-0eee12f2bb3531eab
        description: Deep Learning AMI GPU PyTorch 2.1.0 (Ubuntu 20.04) 20231103

  max_timeout_seconds: 259200    #
  overhead_time_seconds: 36000   # amount of additional time allowed for the job to complete on aws before the instance is stopped.

  resource_files:               # additional resource files or directories that are made available to benchmark runs on ec2, from remote input or user directory.
    - '{user}/config.yaml'
    - '{user}/frameworks.yaml'
    - '{user}/frameworks_latest.yaml'
    - '{user}/frameworks_2022AG.yaml'
    - '{user}/frameworks_ftt.yaml'
    - '{user}/frameworks_zeroshot.yaml'
    - '{user}/frameworks_zeroshot_v2.yaml'
    - '{user}/frameworks_zeroshot_ftt.yaml'
    - '{user}/frameworks_stackinfo.yaml'
    - '{user}/frameworks_tabrepo.yaml'
    - '{user}/frameworks_autogluon_v1.yaml'
    - '{user}/constraints.yaml'
    - '{user}/benchmarks'
    - '{user}/extensions'

#inference_time_measurements:  # configuration namespace for performing additional inference time measurements on various batch sizes
#  enabled: true
